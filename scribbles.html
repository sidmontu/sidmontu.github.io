<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Siddhartha - Projects</title>

    <!-- Bootstrap core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link href="css/blog.css" rel="stylesheet">

  </head>

  <body>

    <!--<div class="blog-masthead">
      <div class="container">
        <nav class="blog-nav">
          <a class="blog-nav-item" href="index.html">Home</a>
          <a class="blog-nav-item" href="pubs.html">Publications</a>
          <a class="blog-nav-item" href="projects.html">Projects</a>
          <a class="blog-nav-item" href="music.html">Music</a>
          <a class="blog-nav-item active" href="blog.html">Tech Toch</a>
        </nav>
      </div>
    </div>-->

    <nav class="navbar navbar-default navbar-inverse" role="navigation">
	   	<div class="container-fluid" id="navfluid">
	    	<div class="navbar-header">
	        	<button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navigationbar">
	            	<span class="sr-only">Toggle navigation</span>
	            	<span class="icon-bar"></span>
	            	<span class="icon-bar"></span>
	            	<span class="icon-bar"></span>
	            </button>
	            <a class="navbar-brand" href="index.html">Siddhartha</a>
	       	</div>
	       	<div class="collapse navbar-collapse" id="navigationbar">
	           	<ul class="nav navbar-nav">	               	
	               	<li><a class="blog-nav-item" href="index.html">Home</a></li>
			        <li><a class="blog-nav-item" href="pubs.html">Publications</a></li>
			        <li><a class="blog-nav-item" href="blog.html">Blog</a></li>
			        <li><a class="blog-nav-item" href="music.html">Music</a></li>
			        <li class="active"><a class="blog-nav-item active" href="scribbles.html">Scribbles</a></li>
	           	</ul>
	      	</div><!-- /.navbar-collapse -->
	   	</div><!-- /.container-fluid -->
	</nav>

    <div class="container">

      <div class="blog-header">
        <h1 class="blog-title">Scribbles</h1>
        <p class="lead blog-description">Quick cheatsheet/notes on small things that don't really deserve a long writeup.</p>
      </div>

      <h3>Xilinx Tools</h3>
      <p>For some obscure reason, if Xilinx tools (e.g. Vivado) is in your $PATH, some C/C++ projects report build errors - I observed this error from trying to build Ettus RFNoC framework using PyBOMBs. Removing Xilinx tools from the $PATH in a fresh terminal does the trick.</p>

      <br>

      <h3>Tensorpack custom DataFlow class</h3>
      <p>If you have a very large dataset that is dynamically-loaded from disk - i.e. if you keep track of pointers in your get_data() routine to yield data to the trainer at runtime, remember to reset these pointers appropriately at the beginning of the get_data() routine. This is because Tensorpack spawns multiple threads for feeding the Tensorpack trainer at runtime, and without a "reset_state()" function will cause out-of-range memory access errors.</p>

      <h3>Xilinx pblocks</h3>
      <p>Pblock is a physical block to constrain nets to physical areas on the FPGA. Pblocks can be nested, but Xilinx recommend at most one-level of nesting, and to avoid it altogether if possible. Pblock can be shaped into custom shapes (instead of just a rectangle) by clicking on the "add pblock rectangle" option when selecting the pblock you wish to reshape. The pblock properties can be exported to a xdc constraints file automatically using "save constraints as" option under "File". These constraints are basically tcl commands that look something like the following:</p>
      <p style="border:3px; border-style:solid; border-color:#000000; padding: 1em;">
        create_pblock "name you wish to give to the pblock"<br>
        add_cells_to_pblock [get_pblocks "name of pblock"] [get_cells -quiet [list "name of module you wish to assign to pblock"]<br>
        resize_pblock [get_pblocks "name of pblock"] -add {SLICE_"XY-COORD":SLICE_"XY-COORD"}<br>
        resize_pblock [get_pblocks "name of pblock"] -add {DSP48_"XY-COORD":DSP48_"XY-COORD"}<br>
        resize_pblock [get_pblocks "name of pblock"] -add {RAMB18_"XY-COORD":RAMB18_"XY-COORD"}<br>
        resize_pblock [get_pblocks "name of pblock"] -add {RAMB36_"XY-COORD":RAMB36_"XY-COORD"}<br>
      </p>
      <p>You can do a DRC check for floorplanning to make sure pblock specified for the module meets expectations. Basically, this is a sanity test.</p>
      <p>Vivado has an auto-floorplanning tool as well (under Tools - Floorplanning - Auto-create Pblocks). Also worth checking out "Window - Phyiscal Constraints" tab, which will show connectivity between different Pblocks for better visualization of dataflow in your circuit. Individual logic can also be locked into exact locations so that there is consistency between runs (i.e. you don't get a completely different placed/routed solution that you can't quantify whether your changes made any difference between implementation runs).</p>
      <p>Floorplanning can improve performance and consistency between runs. Some guidelines: floorplan what is necessary, do not over-floorplan. Choose modules to floor-plan that do not have connectivity to lots of other modules, as those modules are better to be broken apart to reduce critical path lengths. Use RTL hierarchy, DRC checks, properties and other Vivado tools to judge what is best and how to floorplan. Finally, floorplanning can be an iterative process.</p>
      <p>Reference resource: <a href="https://www.xilinx.com/video/hardware/design-analysis-floorplanning-with-vivado.html">https://www.xilinx.com/video/hardware/design-analysis-floorplanning-with-vivado.html</a></p>

      <h3>Arch Linux + bspwm + sxhkd</h3>
      <p>Weird thing I found that if, instead of using urxvt as the main terminal, you are using termite, then there is a weird idiosyncrasy with how a bspc rule has to be declared. In fact, it seems like urxvt also has an oddity from a stackoverflow post that I saw</p>
      <p>Instead of :</p>
      <p style="border:3px; border-style:solid; border-color=#000000; padding: 1em;">
        bspc rule -a termite state=floating<br>
        bspc rule -a urxvt state=floating
      </p>
      <p>You must declare the following (basically the capitalization) :</p>
      <p style="border:3px; border-style:solid; border-color=#000000; padding: 1em;">
        bspc rule -a Termite state=floating<br>
        bspc rule -a URxvt state=floating
      </p>
      <p>for the rule to register when creating the window. By the way, what's with the weird names (sxhkd, urxvt)?</p>
      <p><font color="#FF0000">Problems:</font> panel does not launch automatically on startx.</p>
      
      <h3>Custom IP on Pynq</h3>
      <p>Tested with Vivado(HLS) 2017.4</p>
      <p>For reference: <a href="https://www.youtube.com/watch?v=Dupyek4NUoI">https://www.youtube.com/watch?v=Dupyek4NUoI</a></p>
      <p>For reference: Pynq-Z1 board part number is xc7z020clg400-1</p>
      <p>For reference: Pynq-Z1 board files from: <a href="https://github.com/cathalmccabe/pynq-z1_board_files">https://github.com/cathalmccabe/pynq-z1_board_files</a> (installation instructions in the .md file in repo)</p>
      <p>Steps (roughly) :</p>
      <p style="border:3px; border-style:solid; border-color=#000000; padding: 1em;">
      1) Easiest way is to start with VivadoHLS, write your own HLS module that interfaces with the host CPU. Add HLS INTERFACE pragmas to define the I/O ports and their types. e.g. #pragma HLS INTERFACE s_axilite port=<port_name>. You can choose axi, s_axilite, axis for port type (as far as I know for now). Also add #pragma HLS INTERFACE ap_ctrl_none port=return to turn off function call handshake, which creates a whole bunch of extra ports like ap_start, ap_done, ap_idle, and ap_ready, which might not be required. See <a href="https://www.xilinx.com/support/answers/55279.html">https://www.xilinx.com/support/answers/55279.html</a> for more info.<br>
      2) Run C synthesis, make sure there are no errors and you understand the warnings.<br>
      3) Click button for "Export RTL". We can use default settings and click ok. This will package your design as an IP. Choose the language you prefer as well (I go with Verilog mostly).<br>
      4) This is the first interesting part to pay attention to: Under "solution1" folder (assuming you're using the default solution name for Vivado synthesis process), go to impl>misc>drivers>"your ip name">src and open x"ip name"_hw.h. Make a note of all the addresses of each register that is being assigned to your ports. You'll need this later to be able to write your software Python drivers that send data to these memory-mapped AXI ports.<br>
      5) Switch over to Vivado.

      <h3>AXI-STREAM interface on Pynq (with DMA)</h3>
      <p>Obscure artifact #1: Interrupts from AXI DMA block have to be handled by an AXI Interrupt controller, instead of simply concat into IRQ_F2P port of Zynq-PS. See <a href="https://forums.xilinx.com/t5/Embedded-Linux/A-key-error-when-I-am-trying-to-access-a-DMA-IP-on-PYNQ-Z1-board/td-p/847817">https://forums.xilinx.com/t5/Embedded-Linux/A-key-error-when-I-am-trying-to-access-a-DMA-IP-on-PYNQ-Z1-board/td-p/847817</a></p>

      <h3>DFT/FFT footnotes</h3>
      <p>Mostly grabbed from a great semi-technical summary in a reddit comment, Source: <a href="https://www.reddit.com/r/explainlikeimfive/comments/9cbi8p/eli5_what_is_the_fast_fourier_transform_or_fft/e5axg1n/">https://www.reddit.com/r/explainlikeimfive/comments/9cbi8p/eli5_what_is_the_fast_fourier_transform_or_fft/e5axg1n/</a>

      <ul>
        <li>
        The DFT is N dot products of N sized vectors, which means its computational complexity is <var>N<sup>2</sup></var>. That means doubling your DFT precision results in quadrupling the number of computations.
        </li>

        <li>
          The key to the FFT is exploiting the symmetry of the transform kernel, one of the vectors used in the dot product. This allows you to break up your N sized DFT into two N/2 sized DFTs. IE if you have a 128 sized DFT, you can compute it with two 64 sized DFTs, which can be broken to two 32 sized DFTs, and down into two 16 sized, to two 8 sized, etc. This changes the complexity into <var>Nlog<sub>2</sub>(N)</var> computational complexity. <b>The smallest size FFT you take is called the "radix," which can be 2, 4, 8 etc.</b>
        </li>

        <li>
          To get non power of two sized DFTs you use a "mixed" radix, meaning you factor it into 2, 3, 4, 5, etc sized chunks.
        </li>

        <li>
          There are additional optimizations. The first is for a real valued input, the output is symmetric. Meaning if you want to take a 256 sized FFT of real valued inputs (audio, images, stock prices, whatever), you get a 256 sized output with the same values symmetric about the midpoint. So you only need to compute half as many outputs.
        </li>

        <li>
          The next optimization has to do with what are called SIMD operations, single instruction multiple data. If you're familiar with GPUs, this is what makes them fast. The DFT is stateless, meaning that a given output point for a particular radix doesn't depend on any other outputs or inputs. This allows you to compute multiple outputs points of the DFT simultaneously.
        </li>

        <li>
          Another big optimization that pops up in terminology is "in place" versus "out of place" FFTs. An "in place" FFT writes the output values to the same memory used for the input, this makes the memory complexity O(1) instead of O(N) and it's a major speedup on modern processors, and also critical on embedded systems with limited memory.
        </li>

        <li>
          A twiddle factor is a coefficient constant that is precomputed and multiplied with the real data. This is relevant to the recursive Cooley-Tukey (actually, really Gauss) algorithm for doing FFT (instead of the O(<var>N<sup>2</<sup></var>) DFT).
        </li>
        <li>
          There are a bunch of other tricks to speed up the FFT, like bit twiddling techniques (note: this is not related to twiddle factors described above) on the vector indices to reduce intermediate computations. Generally, this is useful to in-place FFTs (see definition in point above), which are quite challenging to optimize. This is because the destination address being written to does not necessarily swap with the source value being used for the computation. Hence, this requires a permutation computation that trades-off runtime for savings in memory usage. Unfortunately, these permutations can prevent the compiler from recognizing "shared code" in these recursive calls to the FFT algorithm, such as reuse of trigonometric constants. One example is doing a bit-reversal permutation. E.g. FFT-8 inputs can be arranged in natural order, i.e. [0,1,2,3,4,5,6,7]. Each of those indices can be represeted as a 3b number, i.e. [000,001,010,011,100,101,110,111]. By doing a bit-reversal on those 3b, we can compute a new permutation which looks like [000,100,010,110,001,101,011,111], which is [0,4,2,6,1,5,3,7]. Note how this bit-reversal technique has collected all the even indices to the front, and odd-indices to the back. This guarantees the correctness of executing the recursive FFT algorithm, and saves computation time for index calculation.
        </li>

        <li>
          Lastly there are some very useful properties of the FFT that make it crucial for modern applications. The first is that the DFT isn't special in and of itself, rather it's a member of a family of operations called Finite Length Orthogonal Transforms, and for a subset of that family the FFT algorithm can be tweaked to compute those other operations. One of the most popular is the DCT, or discrete cosine transform. This is used in almost every lossy compression codec.
        </li>

        <li>
          Finally going back to that convolution issue you brought up, that is the operation used for some filtering (think blurring in images, among other tricks). For large filter lengths, the FFT can be used to implement them faster than linear convolution.  
        </li>
      </ul>

    </div><!-- /.container -->

    <footer class="blog-footer">
      <p>Blog template built for <a href="http://getbootstrap.com" target="_blank">Bootstrap</a> by <a href="https://twitter.com/mdo" target="_blank">@mdo</a>.</p>
      <p>
        <a href="#">Back to top</a>
      </p>
    </footer>


    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="js/script.js"></script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="js/bootstrap.min.js"></script>
    </body>
</html>
